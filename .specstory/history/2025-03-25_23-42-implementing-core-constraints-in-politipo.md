<!-- Generated by SpecStory -->

# Implementing Core Constraints in Politipo (2025-03-25 20:42:58)

_**User**_

@politipo @ABOUT_POLITIPO.md 

Plesae understand deeply the codebase and help me apply:

```
Okay, here is the code for `Task Core-1`, implementing the additional core constraints.

This involves modifying `politipo/core/types/constraints.py` and updating `politipo/core/types/__init__.py`.

**1. Updated `politipo/core/types/constraints.py`:**

```python
# ./politipo/core/types/constraints.py

from dataclasses import dataclass
from typing import Any, Dict, Type, TypeVar
import re  # Import regex module

# Import base class and error from the new structure
from .abstract import Constraint
from ..errors import ConstraintViolationError

C = TypeVar('C', bound='Constraint') # Type variable for from_dict


@dataclass(frozen=True)
class GreaterThanOrEqual(Constraint):
    """Numeric greater than or equal constraint (inclusive minimum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the minimum constraint (inclusive).

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too small
        """
        try:
            numeric_val = float(val) # Attempt conversion here
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val < self.value:
            raise ConstraintViolationError(
                f"Value {val} is less than minimum allowed {self.value} (inclusive)"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "ge", "value": self.value} # Use 'ge' for consistency with Pydantic

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class GreaterThan(Constraint):
    """Numeric greater than constraint (exclusive minimum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value is strictly greater than the specified minimum.

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or not strictly greater
        """
        try:
            numeric_val = float(val)
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val <= self.value:
            raise ConstraintViolationError(
                f"Value {val} is not strictly greater than {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "gt", "value": self.value} # Use 'gt'

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class LessThanOrEqual(Constraint):
    """Numeric less than or equal constraint (inclusive maximum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the maximum constraint (inclusive).

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too large
        """
        try:
            numeric_val = float(val)
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val > self.value:
            raise ConstraintViolationError(
                f"Value {val} is greater than maximum allowed {self.value} (inclusive)"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "le", "value": self.value} # Use 'le'

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class LessThan(Constraint):
    """Numeric less than constraint (exclusive maximum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value is strictly less than the specified maximum.

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or not strictly smaller
        """
        try:
            numeric_val = float(val)
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val >= self.value:
            raise ConstraintViolationError(
                f"Value {val} is not strictly less than {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "lt", "value": self.value} # Use 'lt'

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class MinLength(Constraint):
    """String/collection minimum length constraint."""
    value: int

    def __post_init__(self):
        """Validate value during initialization."""
        if not isinstance(self.value, int):
            raise TypeError(f"{self.__class__.__name__} requires an integer value, got {type(self.value)}")
        if self.value < 0:
            raise ValueError(f"{self.__class__.__name__} value must be non-negative, got {self.value}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the minimum length constraint.

        Args:
            val: Value to validate (should support `len()`)

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too short
        """
        try:
            length = len(val)
        except TypeError as e:
            raise ConstraintViolationError(
                f"Value '{val}' (type: {type(val)}) does not support length checking for {self.__class__.__name__}."
            ) from e

        if length < self.value:
            raise ConstraintViolationError(
                f"Length {length} is less than minimum allowed {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "min_length", "value": self.value}

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=int(data["value"]))
        except (TypeError, ValueError) as e:
            raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class MaxLength(Constraint):
    """String/collection maximum length constraint."""
    value: int

    def __post_init__(self):
        """Validate value during initialization."""
        if not isinstance(self.value, int):
            raise TypeError(f"{self.__class__.__name__} requires an integer value, got {type(self.value)}")
        if self.value < 0:
            raise ValueError(f"{self.__class__.__name__} value must be non-negative, got {self.value}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the maximum length constraint.

        Args:
            val: Value to validate (should support `len()`)

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too long
        """
        try:
            length = len(val)
        except TypeError as e:
            raise ConstraintViolationError(
                f"Value '{val}' (type: {type(val)}) does not support length checking for {self.__class__.__name__}."
            ) from e

        if length > self.value:
            raise ConstraintViolationError(
                f"Length {length} exceeds maximum allowed {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "max_length", "value": self.value}

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=int(data["value"]))
        except (TypeError, ValueError) as e:
            raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class Pattern(Constraint):
    """String pattern constraint (regex)."""
    regex: str
    _compiled_regex: re.Pattern = None # Cache compiled regex

    def __post_init__(self):
        """Validate regex during initialization."""
        if not isinstance(self.regex, str) or not self.regex:
            raise TypeError(f"{self.__class__.__name__} requires a non-empty string regex pattern, got {type(self.regex)}")
        try:
            # Use object.__setattr__ because the dataclass is frozen
            object.__setattr__(self, '_compiled_regex', re.compile(self.regex))
        except re.error as e:
            raise ValueError(f"Invalid regex pattern for {self.__class__.__name__}: '{self.regex}' - {e}") from e

    def validate(self, val: Any) -> bool:
        """
        Validate that a string value matches the regex pattern (full match).

        Args:
            val: Value to validate

        Returns:
            True if value matches pattern

        Raises:
            ConstraintViolationError: If value is not a string or does not match
        """
        try:
            # Attempt to convert value to string for validation
            str_val = str(val)
        except Exception as e:
             raise ConstraintViolationError(
                f"Value '{val}' cannot be converted to string for {self.__class__.__name__} validation."
            ) from e

        # Use fullmatch for stricter validation, similar to Pydantic's constr
        if not self._compiled_regex.fullmatch(str_val):
            raise ConstraintViolationError(
                f"Value '{str_val}' does not match pattern '{self.regex}'"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "pattern", "regex": self.regex}

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "regex" not in data or not isinstance(data["regex"], str):
            raise ValueError(f"{cls.__name__} requires a string 'regex' parameter in data")
        # Validation happens in __post_init__
        return cls(regex=data["regex"])


# Registry for constraint deserialization with type safety
# Using keys consistent with Pydantic where applicable (ge, gt, le, lt)
_CONSTRAINT_REGISTRY: Dict[str, Type[Constraint]] = {
    "ge": GreaterThanOrEqual,
    "gt": GreaterThan,
    "le": LessThanOrEqual,
    "lt": LessThan,
    "min_length": MinLength,
    "max_length": MaxLength,
    "pattern": Pattern,
    # Add aliases if needed, e.g. "min_value": GreaterThanOrEqual
}


def constraint_from_dict(data: Dict[str, Any]) -> Constraint:
    """
    Factory method for deserializing constraints.

    Args:
        data: Dictionary representation of constraint, must include 'type' key.

    Returns:
        Instantiated constraint object.

    Raises:
        ValueError: If constraint 'type' is unknown or data is invalid for the type.
    """
    if not isinstance(data, dict):
        raise ValueError(f"Constraint data must be a dictionary, got {type(data)}")

    try:
        constraint_type_key = data["type"]
    except KeyError as e:
        raise ValueError("Constraint data must include a 'type' key") from e

    if constraint_type_key not in _CONSTRAINT_REGISTRY:
        raise ValueError(f"Unknown constraint type key: '{constraint_type_key}'. Available: {list(_CONSTRAINT_REGISTRY.keys())}")

    constraint_class = _CONSTRAINT_REGISTRY[constraint_type_key]

    try:
        # The class method 'from_dict' handles specific validation and instantiation
        return constraint_class.from_dict(data)
    except Exception as e:
        # Catch potential errors during instantiation (e.g., invalid value types)
        raise ValueError(f"Failed to create constraint '{constraint_type_key}' from data: {data} - {e}") from e

```

**2. Updated `politipo/core/types/__init__.py`:**

```python
# ./politipo/core/types/__init__.py

from .canonical import CanonicalType
from .abstract import Constraint, TypeMeta
from .protocols import TypeSystem, ConstraintProtocol
from .constraints import (
    GreaterThanOrEqual, # Renamed/Replaced MinValue
    GreaterThan,        # New
    LessThanOrEqual,    # New
    LessThan,           # New
    MinLength,          # New
    MaxLength,          # Existing
    Pattern,            # New
    constraint_from_dict
)

__all__ = [
    "CanonicalType",
    "Constraint",
    "TypeMeta",
    "TypeSystem",
    "ConstraintProtocol",
    # List all concrete constraint classes for export
    "GreaterThanOrEqual",
    "GreaterThan",
    "LessThanOrEqual",
    "LessThan",
    "MinLength",
    "MaxLength",
    "Pattern",
    "constraint_from_dict"
]

```

**Explanation of Changes:**

1.  **Renamed `MinValue`:** The original `MinValue` class functionally implemented `greater_than_or_equal`. It has been renamed to `GreaterThanOrEqual` for clarity and consistency. Its type key in `to_dict` and the registry is now `"ge"`.
2.  **Added New Classes:** `GreaterThan`, `LessThanOrEqual`, `LessThan`, `MinLength`, and `Pattern` classes were added, inheriting from `Constraint`.
3.  **Implementation Details:**
    *   Each class uses `@dataclass(frozen=True)`.
    *   `__post_init__` validates the constraint's *own* parameters (e.g., ensuring length is numeric and non-negative).
    *   `validate` methods perform the actual validation against an input value, attempting necessary type conversions (`float()`, `len()`, `str()`) and raising `ConstraintViolationError` on failure or incompatible input types. The `Pattern.validate` uses `re.fullmatch` for stricter matching.
    *   `to_dict` serializes the constraint with a `"type"` key (using Pydantic-like keys `ge`, `gt`, `le`, `lt`, `min_length`, `max_length`, `pattern`) and its value(s).
    *   `from_dict` class methods reconstruct the constraint instance from a dictionary, including basic validation of the dictionary structure and value types.
    *   `Pattern` pre-compiles the regex in `__post_init__` for efficiency and validates the pattern itself early.
4.  **Updated Registry (`_CONSTRAINT_REGISTRY`):** All new and renamed/existing classes are registered with descriptive string keys.
5.  **Updated Factory (`constraint_from_dict`):** This function now uses the updated registry to deserialize constraint objects from dictionaries, providing clearer error messages.
6.  **Updated `__init__.py`:** The `__all__` list in `politipo/core/types/__init__.py` is updated to export all the newly added constraint classes.
```

---

_**Assistant**_

Okay, I understand the changes you want to make. You're expanding the core constraint system in `politipo` by adding more specific numeric and length constraints, plus a regex pattern constraint. This aligns well with the goal of preserving semantic intent and structural constraints during type conversions.

Let's apply these updates.

**1. Update `politipo/core/types/constraints.py`**

I will replace the existing content with the new constraint definitions and update the registry and factory function.

```python:politipo/core/types/constraints.py
from dataclasses import dataclass
from typing import Any, Dict, Type, TypeVar
import re  # Import regex module

# Import base class and error from the new structure
from .abstract import Constraint
from ..errors import ConstraintViolationError

C = TypeVar('C', bound='Constraint') # Type variable for from_dict


@dataclass(frozen=True)
class GreaterThanOrEqual(Constraint):
    """Numeric greater than or equal constraint (inclusive minimum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the minimum constraint (inclusive).

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too small
        """
        try:
            numeric_val = float(val) # Attempt conversion here
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val < self.value:
            raise ConstraintViolationError(
                f"Value {val} is less than minimum allowed {self.value} (inclusive)"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "ge", "value": self.value} # Use 'ge' for consistency with Pydantic

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class GreaterThan(Constraint):
    """Numeric greater than constraint (exclusive minimum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value is strictly greater than the specified minimum.

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or not strictly greater
        """
        try:
            numeric_val = float(val)
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val <= self.value:
            raise ConstraintViolationError(
                f"Value {val} is not strictly greater than {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "gt", "value": self.value} # Use 'gt'

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class LessThanOrEqual(Constraint):
    """Numeric less than or equal constraint (inclusive maximum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the maximum constraint (inclusive).

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too large
        """
        try:
            numeric_val = float(val)
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val > self.value:
            raise ConstraintViolationError(
                f"Value {val} is greater than maximum allowed {self.value} (inclusive)"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "le", "value": self.value} # Use 'le'

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class LessThan(Constraint):
    """Numeric less than constraint (exclusive maximum)."""
    value: float

    def __post_init__(self):
        """Validate value type during initialization."""
        if not isinstance(self.value, (int, float)):
            raise TypeError(f"{self.__class__.__name__} requires a numeric value, got {type(self.value)}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value is strictly less than the specified maximum.

        Args:
            val: Value to validate

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or not strictly smaller
        """
        try:
            numeric_val = float(val)
        except (TypeError, ValueError) as e:
            raise ConstraintViolationError(
                f"Value '{val}' cannot be compared numerically for {self.__class__.__name__} constraint."
            ) from e

        if numeric_val >= self.value:
            raise ConstraintViolationError(
                f"Value {val} is not strictly less than {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "lt", "value": self.value} # Use 'lt'

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=float(data["value"]))
        except (TypeError, ValueError) as e:
             raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class MinLength(Constraint):
    """String/collection minimum length constraint."""
    value: int

    def __post_init__(self):
        """Validate value during initialization."""
        if not isinstance(self.value, int):
            raise TypeError(f"{self.__class__.__name__} requires an integer value, got {type(self.value)}")
        if self.value < 0:
            raise ValueError(f"{self.__class__.__name__} value must be non-negative, got {self.value}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the minimum length constraint.

        Args:
            val: Value to validate (should support `len()`)

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too short
        """
        try:
            length = len(val)
        except TypeError as e:
            raise ConstraintViolationError(
                f"Value '{val}' (type: {type(val)}) does not support length checking for {self.__class__.__name__}."
            ) from e

        if length < self.value:
            raise ConstraintViolationError(
                f"Length {length} is less than minimum allowed {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "min_length", "value": self.value}

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=int(data["value"]))
        except (TypeError, ValueError) as e:
            raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class MaxLength(Constraint):
    """String/collection maximum length constraint."""
    value: int

    def __post_init__(self):
        """Validate value during initialization."""
        if not isinstance(self.value, int):
            raise TypeError(f"{self.__class__.__name__} requires an integer value, got {type(self.value)}")
        if self.value < 0:
            raise ValueError(f"{self.__class__.__name__} value must be non-negative, got {self.value}")

    def validate(self, val: Any) -> bool:
        """
        Validate that a value meets the maximum length constraint.

        Args:
            val: Value to validate (should support `len()`)

        Returns:
            True if value meets constraint

        Raises:
            ConstraintViolationError: If value is invalid or too long
        """
        try:
            length = len(val)
        except TypeError as e:
            raise ConstraintViolationError(
                f"Value '{val}' (type: {type(val)}) does not support length checking for {self.__class__.__name__}."
            ) from e

        if length > self.value:
            raise ConstraintViolationError(
                f"Length {length} exceeds maximum allowed {self.value}"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "max_length", "value": self.value}

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "value" not in data:
            raise ValueError(f"{cls.__name__} requires 'value' parameter in data")
        try:
            return cls(value=int(data["value"]))
        except (TypeError, ValueError) as e:
            raise ValueError(f"Invalid 'value' for {cls.__name__}: {data.get('value')}") from e


@dataclass(frozen=True)
class Pattern(Constraint):
    """String pattern constraint (regex)."""
    regex: str
    _compiled_regex: re.Pattern = None # Cache compiled regex

    def __post_init__(self):
        """Validate regex during initialization."""
        if not isinstance(self.regex, str) or not self.regex:
            raise TypeError(f"{self.__class__.__name__} requires a non-empty string regex pattern, got {type(self.regex)}")
        try:
            # Use object.__setattr__ because the dataclass is frozen
            object.__setattr__(self, '_compiled_regex', re.compile(self.regex))
        except re.error as e:
            raise ValueError(f"Invalid regex pattern for {self.__class__.__name__}: '{self.regex}' - {e}") from e

    def validate(self, val: Any) -> bool:
        """
        Validate that a string value matches the regex pattern (full match).

        Args:
            val: Value to validate

        Returns:
            True if value matches pattern

        Raises:
            ConstraintViolationError: If value is not a string or does not match
        """
        try:
            # Attempt to convert value to string for validation
            str_val = str(val)
        except Exception as e:
             raise ConstraintViolationError(
                f"Value '{val}' cannot be converted to string for {self.__class__.__name__} validation."
            ) from e

        # Use fullmatch for stricter validation, similar to Pydantic's constr
        if not self._compiled_regex.fullmatch(str_val):
            raise ConstraintViolationError(
                f"Value '{str_val}' does not match pattern '{self.regex}'"
            )
        return True

    def to_dict(self) -> Dict[str, Any]:
        """Serialize constraint to dictionary."""
        return {"type": "pattern", "regex": self.regex}

    @classmethod
    def from_dict(cls: Type[C], data: Dict[str, Any]) -> C:
        """Create constraint from dictionary."""
        if "regex" not in data or not isinstance(data["regex"], str):
            raise ValueError(f"{cls.__name__} requires a string 'regex' parameter in data")
        # Validation happens in __post_init__
        return cls(regex=data["regex"])


# Registry for constraint deserialization with type safety
# Using keys consistent with Pydantic where applicable (ge, gt, le, lt)
_CONSTRAINT_REGISTRY: Dict[str, Type[Constraint]] = {
    "ge": GreaterThanOrEqual,
    "gt": GreaterThan,
    "le": LessThanOrEqual,
    "lt": LessThan,
    "min_length": MinLength,
    "max_length": MaxLength,
    "pattern": Pattern,
    # Add aliases if needed, e.g. "min_value": GreaterThanOrEqual
}


def constraint_from_dict(data: Dict[str, Any]) -> Constraint:
    """
    Factory method for deserializing constraints.

    Args:
        data: Dictionary representation of constraint, must include 'type' key.

    Returns:
        Instantiated constraint object.

    Raises:
        ValueError: If constraint 'type' is unknown or data is invalid for the type.
    """
    if not isinstance(data, dict):
        raise ValueError(f"Constraint data must be a dictionary, got {type(data)}")

    try:
        constraint_type_key = data["type"]
    except KeyError as e:
        raise ValueError("Constraint data must include a 'type' key") from e

    if constraint_type_key not in _CONSTRAINT_REGISTRY:
        raise ValueError(f"Unknown constraint type key: '{constraint_type_key}'. Available: {list(_CONSTRAINT_REGISTRY.keys())}")

    constraint_class = _CONSTRAINT_REGISTRY[constraint_type_key]

    try:
        # The class method 'from_dict' handles specific validation and instantiation
        return constraint_class.from_dict(data)
    except Exception as e:
        # Catch potential errors during instantiation (e.g., invalid value types)
        raise ValueError(f"Failed to create constraint '{constraint_type_key}' from data: {data} - {e}") from e
```

**2. Update `politipo/core/types/__init__.py`**

Now, I'll update the imports and the `__all__` list to reflect the changes in `constraints.py`.

```python:politipo/core/types/__init__.py
from .canonical import CanonicalType
from .abstract import Constraint, TypeMeta
from .protocols import TypeSystem, ConstraintProtocol
from .constraints import (
    GreaterThanOrEqual, # Renamed/Replaced MinValue
    GreaterThan,        # New
    LessThanOrEqual,    # New
    LessThan,           # New
    MinLength,          # New
    MaxLength,          # Existing
    Pattern,            # New
    constraint_from_dict
)

__all__ = [
    "CanonicalType",
    "Constraint",
    "TypeMeta",
    "TypeSystem",
    "ConstraintProtocol",
    # List all concrete constraint classes for export
    "GreaterThanOrEqual",
    "GreaterThan",
    "LessThanOrEqual",
    "LessThan",
    "MinLength",
    "MaxLength",
    "Pattern",
    "constraint_from_dict"
]
```

These changes introduce the new constraint classes and make them available for use within the `politipo` core system. The naming convention (`ge`, `gt`, `le`, `lt`) aligns nicely with Pydantic, which should aid interoperability.

---

_**User**_

Okay, the core constraints from Phase 1 look correct. Let's proceed with implementing Phase 2: Pydantic Enhancements.

This involves modifying `politipo/plugins/pydantic/types.py`, creating two new strategy files, and updating `politipo/core/conversion/strategies/__init__.py`.

**1. Updated `politipo/plugins/pydantic/types.py` (Implementing Tasks Pydantic-1, Pydantic-2, Pydantic-3, Pydantic-4):**

```python
# ./politipo/plugins/pydantic/types.py

from typing import Any, Dict, Type, Union, get_origin, get_args, Optional, List, Tuple
import sys
import datetime
import decimal
from functools import lru_cache

# Pydantic imports - use try/except for graceful failure if not installed
try:
    import pydantic
    from pydantic import BaseModel, Field, create_model
    from pydantic_core import PydanticUndefined
    # Try importing v1/v2 specific things carefully
    try:
        # Pydantic v2 FieldInfo
        from pydantic.fields import FieldInfo
    except ImportError:
        # Pydantic v1 FieldInfo is typically part of the field itself
        FieldInfo = None # Placeholder
    try:
        # Pydantic v1 constrained types (for detection/extraction)
        from pydantic.types import conint, confloat, constr
    except ImportError:
        conint = confloat = constr = None # Placeholders
    PYDANTIC_INSTALLED = True
except ImportError:
    # Define dummy classes/values if pydantic is not installed
    PYDANTIC_INSTALLED = False
    class BaseModel: pass
    def Field(*args, **kwargs): return None
    def create_model(*args, **kwargs): return type('DummyModel', (object,), {})
    PydanticUndefined = object()
    FieldInfo = None
    conint = confloat = constr = None

# Politipo core imports
from politipo.core.types import TypeSystem, CanonicalType, Constraint
from politipo.core.types.constraints import ( # Import specific constraint classes
    GreaterThanOrEqual, GreaterThan, LessThanOrEqual, LessThan,
    MinLength, MaxLength, Pattern, constraint_from_dict
)
from politipo.core.errors import ConversionError, PolitipoError


class PydanticTypeSystem(TypeSystem):
    """Type system implementation for Pydantic models with enhanced support."""

    name = "pydantic"

    def __init__(self):
        """Initialize with caches for version and special types."""
        self._pydantic_version = None
        self._pydantic_email_str = PydanticUndefined # Use sentinel
        self._pydantic_secret_str = PydanticUndefined # Use sentinel

    @lru_cache(maxsize=1) # Cache version detection result
    def _get_pydantic_version(self) -> Optional[int]:
        """Detect the Pydantic version being used."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version

        try:
            # Pydantic v2 has model_dump, v1 relies on dict()
            if hasattr(BaseModel, "model_dump"):
                self._pydantic_version = 2
            elif hasattr(BaseModel, "dict"):
                self._pydantic_version = 1
            else:
                # Should not happen with supported Pydantic, but handle gracefully
                self._pydantic_version = None
            return self._pydantic_version
        except Exception: # Broad except for safety during import/attribute checks
             self._pydantic_version = None
             return None

    def _get_pydantic_special_type(self, type_name: str) -> Optional[Type]:
        """Helper to safely import and cache EmailStr/SecretStr."""
        if not PYDANTIC_INSTALLED:
            return None

        cache_attr = f"_pydantic_{type_name.lower()}_str"
        cached_val = getattr(self, cache_attr, PydanticUndefined)

        if cached_val is not PydanticUndefined:
            return cached_val # Return cached value (could be None if import failed)

        try:
            if type_name == "Email":
                from pydantic import EmailStr
                setattr(self, cache_attr, EmailStr)
                return EmailStr
            elif type_name == "Secret":
                from pydantic import SecretStr
                setattr(self, cache_attr, SecretStr)
                return SecretStr
            else:
                 setattr(self, cache_attr, None) # Mark as checked, but unsupported
                 return None
        except (ImportError, AttributeError):
             setattr(self, cache_attr, None) # Mark as checked, import failed
             return None

    def to_canonical(self, type_obj: Type) -> CanonicalType:
        """
        Convert a Pydantic type or model to canonical type.
        Includes support for constraints, special types, and nesting.
        """
        if not PYDANTIC_INSTALLED:
            raise PolitipoError("Pydantic is required for the PydanticTypeSystem.")

        version = self._get_pydantic_version()

        # 1. Handle Model Classes
        # Check if it's a type and subclass of BaseModel
        if isinstance(type_obj, type) and issubclass(type_obj, BaseModel):
            fields_data = {}
            model_fields = {}

            # Get fields based on version
            if version == 2 and hasattr(type_obj, 'model_fields'):
                 model_fields = type_obj.model_fields
            elif version == 1 and hasattr(type_obj, '__fields__'):
                 model_fields = type_obj.__fields__
            else:
                 # Fallback or error if fields cannot be accessed
                 raise ConversionError(f"Could not determine fields for Pydantic model {type_obj.__name__}")

            for name, field in model_fields.items():
                # Get field annotation/type based on version
                if version == 2:
                    field_annotation = field.annotation
                    field_info_obj = field # FieldInfo is the field itself in v2
                    # Determine required status (more complex in v2)
                    is_required = field.is_required()
                elif version == 1:
                    field_annotation = field.outer_type_ # Use outer_type_ for v1
                    field_info_obj = field.field_info # FieldInfo is separate in v1
                    is_required = field.required
                else:
                    raise ConversionError("Unsupported Pydantic version detected.")

                # Recursively get canonical type for the annotation
                canonical_field_type = self._py_type_to_canonical(field_annotation)

                # Extract constraints
                constraints = self._field_to_constraints(field_info_obj, version)

                fields_data[name] = {
                    "type": canonical_field_type, # Already a CanonicalType instance
                    "constraints": constraints, # Dict[str, Constraint instance]
                    "required": is_required
                    # TODO: Add metadata if needed later (e.g., description)
                }

            return CanonicalType(
                kind="composite",
                name=type_obj.__name__,
                params={"fields": fields_data}
                # No top-level constraints for the model itself currently
            )

        # 2. Handle specific non-model Pydantic types (EmailStr, SecretStr)
        email_str_type = self._get_pydantic_special_type("Email")
        if email_str_type and type_obj is email_str_type:
            return CanonicalType(kind="primitive", name="email")

        secret_str_type = self._get_pydantic_special_type("Secret")
        if secret_str_type and type_obj is secret_str_type:
            return CanonicalType(kind="primitive", name="secret")

        # 3. Handle Annotated types (common in v2 for constraints)
        if get_origin(type_obj) is Union and type(None) in get_args(type_obj):
             # Handle Optional[T] - strip Optional and process T
             non_none_type = next(t for t in get_args(type_obj) if t is not type(None))
             # Return canonical type of T, nullability is handled by 'required' in parent model
             return self._py_type_to_canonical(non_none_type)
        elif hasattr(type_obj, '__metadata__') and hasattr(type_obj, '__origin__'): # Check for Annotated
             base_type = get_args(type_obj)[0]
             metadata = getattr(type_obj, '__metadata__', [])
             constraints = {}
             field_info_from_annotated = None
             # Extract constraints primarily from FieldInfo if present in metadata
             for item in metadata:
                  if FieldInfo and isinstance(item, FieldInfo):
                      field_info_from_annotated = item
                      constraints.update(self._field_to_constraints(item, version))
                      break # Assume only one FieldInfo

             # If no FieldInfo found, maybe constraints are directly from annotated_types?
             if not field_info_from_annotated:
                 for item in metadata:
                      # Add logic here if constraints can come directly from things
                      # like Gt(0), MinLen(5) etc. in the metadata tuple
                      pass # Placeholder - primary extraction is via FieldInfo

             # Get canonical type of the base type
             base_canonical = self._py_type_to_canonical(base_type)
             # Combine constraints - TODO: How to merge? For now, just return base + extracted
             # This approach might lose constraint info if base_canonical already had some.
             # A better approach might be needed if combining constraints is required.
             # For now, assume constraints primarily come from the Annotated part.
             base_canonical.constraints.update(constraints) # Modify constraints directly? CanonicalType is frozen. Need to recreate.
             return CanonicalType(
                 kind=base_canonical.kind,
                 name=base_canonical.name,
                 params=base_canonical.params,
                 constraints={**base_canonical.constraints, **constraints}, # Merge constraints
                 meta=base_canonical.meta
             )

        # 4. Fallback to basic Python type mapping for primitives/containers
        return self._py_type_to_canonical(type_obj)


    def from_canonical(self, canonical: CanonicalType) -> Type:
        """
        Create a Pydantic type or model class from canonical type.
        """
        if not PYDANTIC_INSTALLED:
            raise PolitipoError("Pydantic is required for the PydanticTypeSystem.")

        # 1. Handle Composite Types (Models)
        if canonical.kind == "composite" and "fields" in canonical.params:
            model_fields = {}
            try:
                for name, field_data in canonical.params["fields"].items():
                    # Get Python type from canonical field type
                    field_canonical_type = field_data["type"]
                    py_type = self._canonical_to_py_type(field_canonical_type)

                    # Get constraints and convert to Pydantic Field kwargs
                    constraints_dict = field_data.get("constraints", {})
                    field_kwargs = self._constraints_to_field_kwargs(constraints_dict)

                    # Handle optionality / required status
                    is_required = field_data.get("required", True)
                    if not is_required:
                        # Make the type Optional[T] unless it already is
                        if get_origin(py_type) is not Union or type(None) not in get_args(py_type):
                           py_type = Optional[py_type]
                        # Pydantic handles default=None automatically for Optional fields
                        # but we can be explicit if needed, checking if 'default' already set
                        if "default" not in field_kwargs:
                             field_kwargs["default"] = None
                    elif 'default' not in field_kwargs and getattr(pydantic, 'VERSION', '1').startswith('1'):
                         # Pydantic v1 requires Ellipsis (...) for required fields without defaults
                         field_kwargs["default"] = ...
                    elif 'default' not in field_kwargs and getattr(pydantic, 'VERSION', '1').startswith('2'):
                         # Pydantic v2 defaults to required if no default is set
                         pass

                    # Create the field definition tuple for create_model
                    # If field_kwargs is empty, use Ellipsis for required or None for optional
                    default_value = field_kwargs.pop('default', PydanticUndefined)

                    if default_value is PydanticUndefined:
                        # Field(...) handles required status implicitly in V2, need ... in V1
                        if self._get_pydantic_version() == 1:
                             model_fields[name] = (py_type, Field(..., **field_kwargs))
                        else:
                             model_fields[name] = (py_type, Field(**field_kwargs)) # V2 handles required implicitly
                    else:
                         model_fields[name] = (py_type, Field(default=default_value, **field_kwargs))

                # Create the Pydantic model dynamically
                return create_model(canonical.name, **model_fields)

            except Exception as e:
                raise ConversionError(f"Failed to create Pydantic model '{canonical.name}' from canonical type: {e}") from e

        # 2. Handle Primitives and Special Pydantic Types
        elif canonical.kind == "primitive":
            return self._canonical_to_py_type(canonical)

        # 3. Handle Containers (List, Dict, etc.)
        elif canonical.kind == "container":
             return self._canonical_to_py_type(canonical) # Delegate to shared helper

        # Fallback or Error
        else:
            raise ConversionError(f"Cannot create Pydantic type from canonical kind '{canonical.kind}' with name '{canonical.name}'")

    def detect(self, obj: Any) -> bool:
        """Check if object is a Pydantic model instance or class."""
        if not PYDANTIC_INSTALLED:
            return False
        # Check instance first, then class
        return isinstance(obj, BaseModel) or (
            isinstance(obj, type) and issubclass(obj, BaseModel)
        )

    def _py_type_to_canonical(self, py_type: Type) -> CanonicalType:
        """
        Convert basic Python types and standard containers to CanonicalType.
        Handles recursion for containers. Does NOT handle Pydantic Models directly here.
        """
        # Handle Optional[T] - convert T and note optionality elsewhere (e.g., 'required' flag)
        origin = get_origin(py_type)
        if origin is Union:
            args = get_args(py_type)
            if type(None) in args and len(args) == 2:
                # It's Optional[T], process T
                non_none_type = next(t for t in args if t is not type(None))
                return self._py_type_to_canonical(non_none_type)
            # TODO: Handle general Union types if needed?

        # Handle standard containers (List, Dict, Set, Tuple)
        if origin in (list, List, set, tuple, dict, Dict):
            args = get_args(py_type)
            container_name = origin.__name__.lower() if hasattr(origin, '__name__') else str(origin)
            # Use list/dict etc directly if origin is from typing
            if origin is List: container_name = 'list'
            if origin is Dict: container_name = 'dict'

            if container_name == "dict":
                if len(args) == 2:
                    key_type = self._py_type_to_canonical(args[0])
                    value_type = self._py_type_to_canonical(args[1])
                    return CanonicalType(
                        kind="container", name="dict",
                        params={"key_type": key_type, "value_type": value_type}
                    )
                else: # Unparameterized Dict, treat as Dict[Any, Any]
                     any_type = CanonicalType(kind="primitive", name="any")
                     return CanonicalType(kind="container", name="dict", params={"key_type": any_type, "value_type": any_type})
            elif container_name in ("list", "set", "tuple"):
                 if len(args) == 1:
                     item_type = self._py_type_to_canonical(args[0])
                     return CanonicalType(kind="container", name=container_name, params={"item_type": item_type})
                 else: # Unparameterized List/Set/Tuple, treat as List[Any] etc.
                      item_type = CanonicalType(kind="primitive", name="any")
                      return CanonicalType(kind="container", name=container_name, params={"item_type": item_type})

        # Handle primitive types
        type_map: Dict[Type, str] = {
            str: "str",
            int: "int",
            float: "float",
            bool: "bool",
            datetime.date: "date",          # Added Task Pydantic-1
            datetime.datetime: "datetime",  # Added Task Pydantic-1
            decimal.Decimal: "decimal",      # Added Task Pydantic-1
            Any: "any",
            type(None): "null" # Represent NoneType explicitly if needed
        }
        if py_type in type_map:
            return CanonicalType(kind="primitive", name=type_map[py_type])

        # Fallback for unknown types
        return CanonicalType(kind="primitive", name="any", params={"original_type": str(py_type)})

    def _canonical_to_py_type(self, canonical: CanonicalType) -> Type:
        """Convert canonical primitive or container type back to Python type."""

        if canonical.kind == "primitive":
            # Handle special Pydantic types first
            if canonical.name == "email":
                email_type = self._get_pydantic_special_type("Email")
                return email_type if email_type else str # Fallback to str
            if canonical.name == "secret":
                secret_type = self._get_pydantic_special_type("Secret")
                return secret_type if secret_type else str # Fallback to str

            # Handle standard primitives
            type_map: Dict[str, Type] = {
                "str": str,
                "int": int,
                "float": float,
                "bool": bool,
                "date": datetime.date,          # Added Task Pydantic-1
                "datetime": datetime.datetime,  # Added Task Pydantic-1
                "decimal": decimal.Decimal,      # Added Task Pydantic-1
                "any": Any,
                "null": type(None),
            }
            return type_map.get(canonical.name, Any) # Default to Any if unknown

        if canonical.kind == "container":
            container_map = {
                "list": List, # Use typing.List etc. for parameterization
                "set": set, # typing.Set
                "tuple": Tuple, # typing.Tuple
                "dict": Dict # typing.Dict
            }
            container = container_map.get(canonical.name)
            if not container:
                 return Any # Unknown container type

            if canonical.name == "dict":
                 key_type = self._canonical_to_py_type(canonical.params.get("key_type", CanonicalType(kind="primitive", name="any")))
                 value_type = self._canonical_to_py_type(canonical.params.get("value_type", CanonicalType(kind="primitive", name="any")))
                 return Dict[key_type, value_type]
            else: # list, set, tuple
                 item_type = self._canonical_to_py_type(canonical.params.get("item_type", CanonicalType(kind="primitive", name="any")))
                 # Special handling for tuple (variable length vs fixed)
                 if container is Tuple:
                      # Assume variable length tuple unless params specify otherwise
                      return Tuple[item_type, ...]
                 try:
                    return container[item_type]
                 except TypeError: # Handle cases where container might not be subscriptable (e.g., if plain 'set' was used)
                    return Any


        if canonical.kind == "composite":
             # This function shouldn't be called directly for composite (models),
             # as from_canonical handles that separately. But if it is, maybe return Any.
             print(f"Warning: _canonical_to_py_type called for composite type '{canonical.name}'. This should be handled by from_canonical.")
             return Any

        return Any # Fallback for other kinds


    def _field_to_constraints(self, field_info: Any, version: Optional[int]) -> Dict[str, Constraint]:
        """
        Extract constraints from a Pydantic FieldInfo object (or v1 field).
        Returns a dictionary mapping constraint type name to Constraint instance.
        """
        constraints: Dict[str, Constraint] = {}
        if field_info is None:
            return constraints

        # Use helper to extract raw constraint values based on version
        raw_constraints = self._get_pydantic_field_raw_constraints(field_info, version)

        # Convert raw values to Constraint objects
        if raw_constraints.get("ge") is not None:
            constraints["ge"] = GreaterThanOrEqual(value=raw_constraints["ge"])
        if raw_constraints.get("gt") is not None:
            constraints["gt"] = GreaterThan(value=raw_constraints["gt"])
        if raw_constraints.get("le") is not None:
            constraints["le"] = LessThanOrEqual(value=raw_constraints["le"])
        if raw_constraints.get("lt") is not None:
            constraints["lt"] = LessThan(value=raw_constraints["lt"])
        if raw_constraints.get("min_length") is not None:
            constraints["min_length"] = MinLength(value=raw_constraints["min_length"])
        if raw_constraints.get("max_length") is not None:
            constraints["max_length"] = MaxLength(value=raw_constraints["max_length"])
        if raw_constraints.get("pattern") is not None:
            constraints["pattern"] = Pattern(regex=raw_constraints["pattern"])
        # Add other constraints here (e.g., multiple_of) if needed

        return constraints

    def _get_pydantic_field_raw_constraints(self, field_info: Any, version: Optional[int]) -> Dict[str, Any]:
        """
        Helper to get raw constraint values from FieldInfo/field based on Pydantic version.
        (Simplified version based on old TypeMapper._get_pydantic_field_constraints)
        """
        raw_constraints = {}
        if field_info is None:
            return raw_constraints

        if version == 2 and FieldInfo and isinstance(field_info, FieldInfo):
             # Pydantic v2: Check metadata and direct attributes
             if hasattr(field_info, "metadata") and field_info.metadata:
                 for item in field_info.metadata:
                      # Simplified check for common constraint types from annotated_types
                      # This could be made more robust by checking specific types
                      if hasattr(item, "gt"): raw_constraints["gt"] = item.gt
                      if hasattr(item, "ge"): raw_constraints["ge"] = item.ge
                      if hasattr(item, "lt"): raw_constraints["lt"] = item.lt
                      if hasattr(item, "le"): raw_constraints["le"] = item.le
                      if hasattr(item, "min_length"): raw_constraints["min_length"] = item.min_length
                      if hasattr(item, "max_length"): raw_constraints["max_length"] = item.max_length
                      if hasattr(item, "pattern"): raw_constraints["pattern"] = item.pattern

             # Check direct attributes as fallback or primary source
             for key in ["gt", "ge", "lt", "le", "min_length", "max_length", "pattern"]:
                 if key not in raw_constraints and hasattr(field_info, key):
                      value = getattr(field_info, key)
                      # Pydantic v2 sometimes uses PydanticUndefined
                      if value is not None and value is not PydanticUndefined:
                           raw_constraints[key] = value

             # Check json_schema_extra
             if hasattr(field_info, "json_schema_extra") and isinstance(field_info.json_schema_extra, dict):
                  for key in ["gt", "ge", "lt", "le", "min_length", "max_length", "pattern"]:
                       if key not in raw_constraints and key in field_info.json_schema_extra:
                            raw_constraints[key] = field_info.json_schema_extra[key]

        elif version == 1:
             # Pydantic v1: Check attributes on field_info and potentially __constraints__ on type
             v1_field_info = getattr(field_info, 'field_info', field_info) # Get FieldInfo if available

             for key in ["gt", "ge", "lt", "le", "min_length", "max_length"]:
                  if hasattr(v1_field_info, key) and getattr(v1_field_info, key) is not None:
                       raw_constraints[key] = getattr(v1_field_info, key)
             if hasattr(v1_field_info, "regex") and v1_field_info.regex is not None:
                  raw_constraints["pattern"] = v1_field_info.regex # Map regex to pattern

             # Check __constraints__ on the field's type (for conint etc.)
             field_type = getattr(field_info, 'outer_type_', None)
             if field_type and hasattr(field_type, '__constraints__') and isinstance(field_type.__constraints__, dict):
                  # Merge constraints, potentially overwriting field_info ones if more specific
                  # Be careful with merging logic if needed
                  for key, value in field_type.__constraints__.items():
                       if key not in raw_constraints: # Avoid overwriting for now
                           if key == 'regex': key = 'pattern' # Normalize
                           raw_constraints[key] = value
        else:
            # Cannot determine constraints for unknown/unsupported version
            pass

        return raw_constraints


    def _constraints_to_field_kwargs(self, constraints: Dict[str, Constraint]) -> Dict[str, Any]:
        """Convert core Constraint objects back to Pydantic Field keyword arguments."""
        kwargs = {}
        if not constraints:
            return kwargs

        for key, constraint in constraints.items():
            # Map based on the type of the Constraint object
            if isinstance(constraint, GreaterThanOrEqual): kwargs["ge"] = constraint.value
            elif isinstance(constraint, GreaterThan): kwargs["gt"] = constraint.value
            elif isinstance(constraint, LessThanOrEqual): kwargs["le"] = constraint.value
            elif isinstance(constraint, LessThan): kwargs["lt"] = constraint.value
            elif isinstance(constraint, MinLength): kwargs["min_length"] = constraint.value
            elif isinstance(constraint, MaxLength): kwargs["max_length"] = constraint.value
            elif isinstance(constraint, Pattern): kwargs["pattern"] = constraint.regex
            # Add mappings for other constraints if they are added

        return kwargs
```

**2. New File `politipo/core/conversion/strategies/pydantic_to_dict.py` (Implementing Task Pydantic-5):**

```python
# ./politipo/core/conversion/strategies/pydantic_to_dict.py

from typing import Any, Dict, Optional

try:
    from pydantic import BaseModel
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.engine import ConversionContext
from politipo.core.errors import ConversionError, PolitipoError


class PydanticToDictStrategy(ConversionStrategy):
    """Strategy for converting Pydantic model instances to Python dictionaries."""

    def __init__(self):
        self._pydantic_version = None # Cache version

    def _get_pydantic_version(self) -> Optional[int]:
        """Detect Pydantic version (cached)."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version
        try:
            if hasattr(BaseModel, "model_dump"): self._pydantic_version = 2
            elif hasattr(BaseModel, "dict"): self._pydantic_version = 1
            else: self._pydantic_version = None
            return self._pydantic_version
        except Exception:
            self._pydantic_version = None
            return None

    def can_handle(self, source: CanonicalType, target: CanonicalType) -> bool:
        """
        Check if this strategy can handle the conversion.
        Source must be a Pydantic model, target must be a dictionary.
        """
        # Check source is likely a Pydantic model (composite type)
        is_source_pydantic = (
            source.kind == "composite" and
            source.params.get("fields") is not None
            # We might need context.source_type_system.name == 'pydantic'
            # but source CanonicalType might not always originate directly from it.
            # Relying on structure for now.
        )
        # Check target is a dictionary
        is_target_dict = (target.kind == "container" and target.name == "dict")

        return is_source_pydantic and is_target_dict and PYDANTIC_INSTALLED

    def convert(self, value: Any, context: ConversionContext) -> Dict[str, Any]:
        """
        Perform the conversion from Pydantic model to dict.
        """
        if not PYDANTIC_INSTALLED:
             raise PolitipoError("Pydantic must be installed to use PydanticToDictStrategy.")
        if not isinstance(value, BaseModel):
             raise ConversionError(f"Input value is not a Pydantic BaseModel instance, got {type(value)}")

        version = self._get_pydantic_version()

        try:
            if version == 2:
                # Use model_dump for Pydantic v2
                # Consider dump options if needed (e.g., mode='json' vs 'python', exclude_none=True)
                return value.model_dump(mode='python') # mode='python' is usually desired for internal dicts
            elif version == 1:
                # Use dict() for Pydantic v1
                # Consider dict options if needed (e.g., exclude_none=True)
                return value.dict()
            else:
                raise ConversionError("Cannot determine Pydantic version for conversion.")
        except Exception as e:
            # Catch potential errors during dump/dict call
            raise ConversionError(f"Failed to convert Pydantic model to dict: {e}") from e

```

**3. New File `politipo/core/conversion/strategies/dict_to_pydantic.py` (Implementing Task Pydantic-6):**

```python
# ./politipo/core/conversion/strategies/dict_to_pydantic.py

from typing import Any, Dict, Optional, Type

try:
    from pydantic import BaseModel, ValidationError
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy
    class ValidationError(Exception): pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.engine import ConversionContext
from politipo.core.errors import ConversionError, ConstraintViolationError, PolitipoError


class DictToPydanticStrategy(ConversionStrategy):
    """Strategy for converting Python dictionaries to Pydantic model instances."""

    def __init__(self):
        self._pydantic_version = None # Cache version

    def _get_pydantic_version(self) -> Optional[int]:
        """Detect Pydantic version (cached)."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version
        try:
            # Use model_validate (v2) vs parse_obj (v1) as indicator
            if hasattr(BaseModel, "model_validate"): self._pydantic_version = 2
            elif hasattr(BaseModel, "parse_obj"): self._pydantic_version = 1
            else: self._pydantic_version = None
            return self._pydantic_version
        except Exception:
             self._pydantic_version = None
             return None

    def can_handle(self, source: CanonicalType, target: CanonicalType) -> bool:
        """
        Check if this strategy can handle the conversion.
        Source must be dict, target must be Pydantic model.
        """
        is_source_dict = (source.kind == "container" and source.name == "dict")
        is_target_pydantic = (
            target.kind == "composite" and
            target.params.get("fields") is not None
            # Could add check: context.target_type_system.name == 'pydantic'
        )
        return is_source_dict and is_target_pydantic and PYDANTIC_INSTALLED

    def convert(self, value: Any, context: ConversionContext) -> BaseModel:
        """
        Perform the conversion from dict to Pydantic model instance.
        """
        if not PYDANTIC_INSTALLED:
             raise PolitipoError("Pydantic must be installed to use DictToPydanticStrategy.")
        if not isinstance(value, dict):
             raise ConversionError(f"Input value is not a dictionary, got {type(value)}")

        version = self._get_pydantic_version()

        try:
            # Get the target Pydantic model class from the TypeSystem
            target_model_class: Type[BaseModel] = context.target_type_system.from_canonical(context.target)
            if not isinstance(target_model_class, type) or not issubclass(target_model_class, BaseModel):
                 raise ConversionError(f"Target type '{context.target.name}' did not resolve to a Pydantic BaseModel class.")

            # Perform validation and instantiation based on version
            if version == 2:
                # Use model_validate for Pydantic v2
                # Consider strict mode from context? model_validate has its own context handling.
                instance = target_model_class.model_validate(value, strict=context.strict)
            elif version == 1:
                # Use parse_obj for Pydantic v1 (no explicit strict mode here)
                if context.strict:
                     # V1 strictness is less granular, parse_obj is inherently coercive
                     # We might need custom pre-validation if strict V1 is desired
                     print("Warning: Strict mode has limited effect in Pydantic v1 DictToPydanticStrategy.")
                instance = target_model_class.parse_obj(value)
            else:
                raise ConversionError("Cannot determine Pydantic version for conversion.")

            # TODO: Consider explicit handling for nested dict-to-model conversion if needed.
            # Pydantic usually handles dicts for nested models well during validation.
            # If issues arise, logic similar to TypeConverter._process_nested_pydantic_fields
            # might be needed here before calling validate/parse_obj.

            return instance

        except ValidationError as e:
            # Wrap Pydantic's validation error in our hierarchy
            # Distinguish between strict mode and non-strict mode behavior
            error_msg = f"Validation failed converting dict to Pydantic model '{target_model_class.__name__}': {e}"
            if context.strict:
                raise ConstraintViolationError(error_msg) from e
            else:
                # In non-strict mode, perhaps log a warning and return None or partial object?
                # For now, let's still raise, but maybe a different error type or logging.
                # Raising ConstraintViolationError seems appropriate even if not strict, as data didn't fit.
                print(f"Warning: {error_msg}") # Log warning in non-strict
                raise ConstraintViolationError(error_msg) from e # Or decide on alternative non-strict handling
        except Exception as e:
            # Catch other potential errors (e.g., TypeSystem issues, unexpected errors)
            raise ConversionError(f"Failed to convert dict to Pydantic model '{context.target.name}': {e}") from e

```

**4. Updated `politipo/core/conversion/strategies/__init__.py`:**

```python
# ./politipo/core/conversion/strategies/__init__.py

from .base import ConversionStrategy
from .pandas_to_pydantic import DataFrameToModelStrategy
from .pydantic_to_dict import PydanticToDictStrategy # Added
from .dict_to_pydantic import DictToPydanticStrategy # Added

__all__ = [
    "ConversionStrategy",
    "DataFrameToModelStrategy",
    "PydanticToDictStrategy", # Added
    "DictToPydanticStrategy", # Added
    # Add other future strategies here
]
```

**Summary of Phase 2 Implementation:**

*   **`PydanticTypeSystem`:** Enhanced to handle `date`, `datetime`, `decimal`, `EmailStr`, `SecretStr`. Added Pydantic v1/v2 version detection. Significantly improved constraint mapping in both directions (`_field_to_constraints`, `_constraints_to_field_kwargs`) using the new core `Constraint` classes and version awareness. Updated `to_canonical` to access fields correctly based on version. Updated `from_canonical` to handle optionality and default values more explicitly when creating models.
*   **`PydanticToDictStrategy`:** New strategy to convert Pydantic models to dictionaries, using `model_dump` (v2) or `dict` (v1).
*   **`DictToPydanticStrategy`:** New strategy to convert dictionaries to Pydantic models, using `model_validate` (v2) or `parse_obj` (v1) and basic handling of `context.strict`.
*   **`__init__.py`:** Exported the new strategies.

This completes the implementation for Phase 2 based on the provided tasks. We should now proceed to Phase 3 (SQLAlchemy).

---

_**Assistant**_

Okay, Phase 2 involves enhancing the Pydantic plugin and adding specific conversion strategies for dictionary interactions. Let's apply these changes.

**1. Update `politipo/plugins/pydantic/types.py`**

This file requires significant updates to handle version differences, new types, and improved constraint mapping.

```python:politipo/plugins/pydantic/types.py
from typing import Any, Dict, Type, Union, get_origin, get_args, Optional, List, Tuple
import sys
import datetime
import decimal
from functools import lru_cache

# Pydantic imports - use try/except for graceful failure if not installed
try:
    import pydantic
    from pydantic import BaseModel, Field, create_model
    from pydantic_core import PydanticUndefined
    # Try importing v1/v2 specific things carefully
    try:
        # Pydantic v2 FieldInfo
        from pydantic.fields import FieldInfo
    except ImportError:
        # Pydantic v1 FieldInfo is typically part of the field itself
        FieldInfo = None # Placeholder
    try:
        # Pydantic v1 constrained types (for detection/extraction)
        from pydantic.types import conint, confloat, constr
    except ImportError:
        conint = confloat = constr = None # Placeholders
    PYDANTIC_INSTALLED = True
except ImportError:
    # Define dummy classes/values if pydantic is not installed
    PYDANTIC_INSTALLED = False
    class BaseModel: pass
    def Field(*args, **kwargs): return None
    def create_model(*args, **kwargs): return type('DummyModel', (object,), {})
    PydanticUndefined = object()
    FieldInfo = None
    conint = confloat = constr = None

# Politipo core imports
from politipo.core.types import TypeSystem, CanonicalType, Constraint
from politipo.core.types.constraints import ( # Import specific constraint classes
    GreaterThanOrEqual, GreaterThan, LessThanOrEqual, LessThan,
    MinLength, MaxLength, Pattern, constraint_from_dict
)
from politipo.core.errors import ConversionError, PolitipoError


class PydanticTypeSystem(TypeSystem):
    """Type system implementation for Pydantic models with enhanced support."""

    name = "pydantic"

    def __init__(self):
        """Initialize with caches for version and special types."""
        self._pydantic_version = None
        self._pydantic_email_str = PydanticUndefined # Use sentinel
        self._pydantic_secret_str = PydanticUndefined # Use sentinel

    @lru_cache(maxsize=1) # Cache version detection result
    def _get_pydantic_version(self) -> Optional[int]:
        """Detect the Pydantic version being used."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version

        try:
            # Pydantic v2 has model_dump, v1 relies on dict()
            if hasattr(BaseModel, "model_dump"):
                self._pydantic_version = 2
            elif hasattr(BaseModel, "dict"):
                self._pydantic_version = 1
            else:
                # Should not happen with supported Pydantic, but handle gracefully
                self._pydantic_version = None
            return self._pydantic_version
        except Exception: # Broad except for safety during import/attribute checks
             self._pydantic_version = None
             return None

    def _get_pydantic_special_type(self, type_name: str) -> Optional[Type]:
        """Helper to safely import and cache EmailStr/SecretStr."""
        if not PYDANTIC_INSTALLED:
            return None

        cache_attr = f"_pydantic_{type_name.lower()}_str"
        cached_val = getattr(self, cache_attr, PydanticUndefined)

        if cached_val is not PydanticUndefined:
            return cached_val # Return cached value (could be None if import failed)

        try:
            if type_name == "Email":
                from pydantic import EmailStr
                setattr(self, cache_attr, EmailStr)
                return EmailStr
            elif type_name == "Secret":
                from pydantic import SecretStr
                setattr(self, cache_attr, SecretStr)
                return SecretStr
            else:
                 setattr(self, cache_attr, None) # Mark as checked, but unsupported
                 return None
        except (ImportError, AttributeError):
             setattr(self, cache_attr, None) # Mark as checked, import failed
             return None

    def to_canonical(self, type_obj: Type) -> CanonicalType:
        """
        Convert a Pydantic type or model to canonical type.
        Includes support for constraints, special types, and nesting.
        """
        if not PYDANTIC_INSTALLED:
            raise PolitipoError("Pydantic is required for the PydanticTypeSystem.")

        version = self._get_pydantic_version()

        # 1. Handle Model Classes
        # Check if it's a type and subclass of BaseModel
        if isinstance(type_obj, type) and issubclass(type_obj, BaseModel):
            fields_data = {}
            model_fields = {}

            # Get fields based on version
            if version == 2 and hasattr(type_obj, 'model_fields'):
                 model_fields = type_obj.model_fields
            elif version == 1 and hasattr(type_obj, '__fields__'):
                 model_fields = type_obj.__fields__
            else:
                 # Fallback or error if fields cannot be accessed
                 raise ConversionError(f"Could not determine fields for Pydantic model {type_obj.__name__}")

            for name, field in model_fields.items():
                # Get field annotation/type based on version
                if version == 2:
                    field_annotation = field.annotation
                    field_info_obj = field # FieldInfo is the field itself in v2
                    # Determine required status (more complex in v2)
                    is_required = field.is_required()
                elif version == 1:
                    field_annotation = field.outer_type_ # Use outer_type_ for v1
                    field_info_obj = field.field_info # FieldInfo is separate in v1
                    is_required = field.required
                else:
                    raise ConversionError("Unsupported Pydantic version detected.")

                # Recursively get canonical type for the annotation
                canonical_field_type = self._py_type_to_canonical(field_annotation)

                # Extract constraints
                constraints = self._field_to_constraints(field_info_obj, version)

                fields_data[name] = {
                    "type": canonical_field_type, # Already a CanonicalType instance
                    "constraints": constraints, # Dict[str, Constraint instance]
                    "required": is_required
                    # TODO: Add metadata if needed later (e.g., description)
                }

            return CanonicalType(
                kind="composite",
                name=type_obj.__name__,
                params={"fields": fields_data}
                # No top-level constraints for the model itself currently
            )

        # 2. Handle specific non-model Pydantic types (EmailStr, SecretStr)
        email_str_type = self._get_pydantic_special_type("Email")
        if email_str_type and type_obj is email_str_type:
            return CanonicalType(kind="primitive", name="email")

        secret_str_type = self._get_pydantic_special_type("Secret")
        if secret_str_type and type_obj is secret_str_type:
            return CanonicalType(kind="primitive", name="secret")

        # 3. Handle Annotated types (common in v2 for constraints)
        if get_origin(type_obj) is Union and type(None) in get_args(type_obj):
             # Handle Optional[T] - strip Optional and process T
             non_none_type = next(t for t in get_args(type_obj) if t is not type(None))
             # Return canonical type of T, nullability is handled by 'required' in parent model
             return self._py_type_to_canonical(non_none_type)
        elif hasattr(type_obj, '__metadata__') and hasattr(type_obj, '__origin__'): # Check for Annotated
             base_type = get_args(type_obj)[0]
             metadata = getattr(type_obj, '__metadata__', [])
             constraints = {}
             field_info_from_annotated = None
             # Extract constraints primarily from FieldInfo if present in metadata
             for item in metadata:
                  if FieldInfo and isinstance(item, FieldInfo):
                      field_info_from_annotated = item
                      constraints.update(self._field_to_constraints(item, version))
                      break # Assume only one FieldInfo

             # If no FieldInfo found, maybe constraints are directly from annotated_types?
             if not field_info_from_annotated:
                 for item in metadata:
                      # Add logic here if constraints can come directly from things
                      # like Gt(0), MinLen(5) etc. in the metadata tuple
                      pass # Placeholder - primary extraction is via FieldInfo

             # Get canonical type of the base type
             base_canonical = self._py_type_to_canonical(base_type)
             # Combine constraints - TODO: How to merge? For now, just return base + extracted
             # This approach might lose constraint info if base_canonical already had some.
             # A better approach might be needed if combining constraints is required.
             # For now, assume constraints primarily come from the Annotated part.
             # base_canonical.constraints.update(constraints) # Modify constraints directly? CanonicalType is frozen. Need to recreate.
             return CanonicalType(
                 kind=base_canonical.kind,
                 name=base_canonical.name,
                 params=base_canonical.params,
                 constraints={**base_canonical.constraints, **constraints}, # Merge constraints
                 meta=base_canonical.meta
             )

        # 4. Fallback to basic Python type mapping for primitives/containers
        return self._py_type_to_canonical(type_obj)


    def from_canonical(self, canonical: CanonicalType) -> Type:
        """
        Create a Pydantic type or model class from canonical type.
        """
        if not PYDANTIC_INSTALLED:
            raise PolitipoError("Pydantic is required for the PydanticTypeSystem.")

        # 1. Handle Composite Types (Models)
        if canonical.kind == "composite" and "fields" in canonical.params:
            model_fields = {}
            try:
                for name, field_data in canonical.params["fields"].items():
                    # Get Python type from canonical field type
                    field_canonical_type = field_data["type"]
                    py_type = self._canonical_to_py_type(field_canonical_type)

                    # Get constraints and convert to Pydantic Field kwargs
                    constraints_dict = field_data.get("constraints", {})
                    field_kwargs = self._constraints_to_field_kwargs(constraints_dict)

                    # Handle optionality / required status
                    is_required = field_data.get("required", True)
                    if not is_required:
                        # Make the type Optional[T] unless it already is
                        if get_origin(py_type) is not Union or type(None) not in get_args(py_type):
                           py_type = Optional[py_type]
                        # Pydantic handles default=None automatically for Optional fields
                        # but we can be explicit if needed, checking if 'default' already set
                        if "default" not in field_kwargs:
                             field_kwargs["default"] = None
                    elif 'default' not in field_kwargs and getattr(pydantic, 'VERSION', '1').startswith('1'):
                         # Pydantic v1 requires Ellipsis (...) for required fields without defaults
                         field_kwargs["default"] = ...
                    elif 'default' not in field_kwargs and getattr(pydantic, 'VERSION', '1').startswith('2'):
                         # Pydantic v2 defaults to required if no default is set
                         pass

                    # Create the field definition tuple for create_model
                    # If field_kwargs is empty, use Ellipsis for required or None for optional
                    default_value = field_kwargs.pop('default', PydanticUndefined)

                    if default_value is PydanticUndefined:
                        # Field(...) handles required status implicitly in V2, need ... in V1
                        if self._get_pydantic_version() == 1:
                             model_fields[name] = (py_type, Field(..., **field_kwargs))
                        else:
                             model_fields[name] = (py_type, Field(**field_kwargs)) # V2 handles required implicitly
                    else:
                         model_fields[name] = (py_type, Field(default=default_value, **field_kwargs))

                # Create the Pydantic model dynamically
                return create_model(canonical.name, **model_fields)

            except Exception as e:
                raise ConversionError(f"Failed to create Pydantic model '{canonical.name}' from canonical type: {e}") from e

        # 2. Handle Primitives and Special Pydantic Types
        elif canonical.kind == "primitive":
            return self._canonical_to_py_type(canonical)

        # 3. Handle Containers (List, Dict, etc.)
        elif canonical.kind == "container":
             return self._canonical_to_py_type(canonical) # Delegate to shared helper

        # Fallback or Error
        else:
            raise ConversionError(f"Cannot create Pydantic type from canonical kind '{canonical.kind}' with name '{canonical.name}'")

    def detect(self, obj: Any) -> bool:
        """Check if object is a Pydantic model instance or class."""
        if not PYDANTIC_INSTALLED:
            return False
        # Check instance first, then class
        return isinstance(obj, BaseModel) or (
            isinstance(obj, type) and issubclass(obj, BaseModel)
        )

    def _py_type_to_canonical(self, py_type: Type) -> CanonicalType:
        """
        Convert basic Python types and standard containers to CanonicalType.
        Handles recursion for containers. Does NOT handle Pydantic Models directly here.
        """
        # Handle Optional[T] - convert T and note optionality elsewhere (e.g., 'required' flag)
        origin = get_origin(py_type)
        if origin is Union:
            args = get_args(py_type)
            if type(None) in args and len(args) == 2:
                # It's Optional[T], process T
                non_none_type = next(t for t in args if t is not type(None))
                return self._py_type_to_canonical(non_none_type)
            # TODO: Handle general Union types if needed?

        # Handle standard containers (List, Dict, Set, Tuple)
        if origin in (list, List, set, tuple, dict, Dict):
            args = get_args(py_type)
            container_name = origin.__name__.lower() if hasattr(origin, '__name__') else str(origin)
            # Use list/dict etc directly if origin is from typing
            if origin is List: container_name = 'list'
            if origin is Dict: container_name = 'dict'

            if container_name == "dict":
                if len(args) == 2:
                    key_type = self._py_type_to_canonical(args[0])
                    value_type = self._py_type_to_canonical(args[1])
                    return CanonicalType(
                        kind="container", name="dict",
                        params={"key_type": key_type, "value_type": value_type}
                    )
                else: # Unparameterized Dict, treat as Dict[Any, Any]
                     any_type = CanonicalType(kind="primitive", name="any")
                     return CanonicalType(kind="container", name="dict", params={"key_type": any_type, "value_type": any_type})
            elif container_name in ("list", "set", "tuple"):
                 if len(args) == 1:
                     item_type = self._py_type_to_canonical(args[0])
                     return CanonicalType(kind="container", name=container_name, params={"item_type": item_type})
                 else: # Unparameterized List/Set/Tuple, treat as List[Any] etc.
                      item_type = CanonicalType(kind="primitive", name="any")
                      return CanonicalType(kind="container", name=container_name, params={"item_type": item_type})

        # Handle primitive types
        type_map: Dict[Type, str] = {
            str: "str",
            int: "int",
            float: "float",
            bool: "bool",
            datetime.date: "date",          # Added Task Pydantic-1
            datetime.datetime: "datetime",  # Added Task Pydantic-1
            decimal.Decimal: "decimal",      # Added Task Pydantic-1
            Any: "any",
            type(None): "null" # Represent NoneType explicitly if needed
        }
        if py_type in type_map:
            return CanonicalType(kind="primitive", name=type_map[py_type])

        # Fallback for unknown types
        return CanonicalType(kind="primitive", name="any", params={"original_type": str(py_type)})

    def _canonical_to_py_type(self, canonical: CanonicalType) -> Type:
        """Convert canonical primitive or container type back to Python type."""

        if canonical.kind == "primitive":
            # Handle special Pydantic types first
            if canonical.name == "email":
                email_type = self._get_pydantic_special_type("Email")
                return email_type if email_type else str # Fallback to str
            if canonical.name == "secret":
                secret_type = self._get_pydantic_special_type("Secret")
                return secret_type if secret_type else str # Fallback to str

            # Handle standard primitives
            type_map: Dict[str, Type] = {
                "str": str,
                "int": int,
                "float": float,
                "bool": bool,
                "date": datetime.date,          # Added Task Pydantic-1
                "datetime": datetime.datetime,  # Added Task Pydantic-1
                "decimal": decimal.Decimal,      # Added Task Pydantic-1
                "any": Any,
                "null": type(None),
            }
            return type_map.get(canonical.name, Any) # Default to Any if unknown

        if canonical.kind == "container":
            container_map = {
                "list": List, # Use typing.List etc. for parameterization
                "set": set, # typing.Set
                "tuple": Tuple, # typing.Tuple
                "dict": Dict # typing.Dict
            }
            container = container_map.get(canonical.name)
            if not container:
                 return Any # Unknown container type

            if canonical.name == "dict":
                 key_type = self._canonical_to_py_type(canonical.params.get("key_type", CanonicalType(kind="primitive", name="any")))
                 value_type = self._canonical_to_py_type(canonical.params.get("value_type", CanonicalType(kind="primitive", name="any")))
                 return Dict[key_type, value_type]
            else: # list, set, tuple
                 item_type = self._canonical_to_py_type(canonical.params.get("item_type", CanonicalType(kind="primitive", name="any")))
                 # Special handling for tuple (variable length vs fixed)
                 if container is Tuple:
                      # Assume variable length tuple unless params specify otherwise
                      return Tuple[item_type, ...]
                 try:
                    return container[item_type]
                 except TypeError: # Handle cases where container might not be subscriptable (e.g., if plain 'set' was used)
                    return Any


        if canonical.kind == "composite":
             # This function shouldn't be called directly for composite (models),
             # as from_canonical handles that separately. But if it is, maybe return Any.
             print(f"Warning: _canonical_to_py_type called for composite type '{canonical.name}'. This should be handled by from_canonical.")
             return Any

        return Any # Fallback for other kinds


    def _field_to_constraints(self, field_info: Any, version: Optional[int]) -> Dict[str, Constraint]:
        """
        Extract constraints from a Pydantic FieldInfo object (or v1 field).
        Returns a dictionary mapping constraint type name to Constraint instance.
        """
        constraints: Dict[str, Constraint] = {}
        if field_info is None:
            return constraints

        # Use helper to extract raw constraint values based on version
        raw_constraints = self._get_pydantic_field_raw_constraints(field_info, version)

        # Convert raw values to Constraint objects
        if raw_constraints.get("ge") is not None:
            constraints["ge"] = GreaterThanOrEqual(value=raw_constraints["ge"])
        if raw_constraints.get("gt") is not None:
            constraints["gt"] = GreaterThan(value=raw_constraints["gt"])
        if raw_constraints.get("le") is not None:
            constraints["le"] = LessThanOrEqual(value=raw_constraints["le"])
        if raw_constraints.get("lt") is not None:
            constraints["lt"] = LessThan(value=raw_constraints["lt"])
        if raw_constraints.get("min_length") is not None:
            constraints["min_length"] = MinLength(value=raw_constraints["min_length"])
        if raw_constraints.get("max_length") is not None:
            constraints["max_length"] = MaxLength(value=raw_constraints["max_length"])
        if raw_constraints.get("pattern") is not None:
            constraints["pattern"] = Pattern(regex=raw_constraints["pattern"])
        # Add other constraints here (e.g., multiple_of) if needed

        return constraints

    def _get_pydantic_field_raw_constraints(self, field_info: Any, version: Optional[int]) -> Dict[str, Any]:
        """
        Helper to get raw constraint values from FieldInfo/field based on Pydantic version.
        (Simplified version based on old TypeMapper._get_pydantic_field_constraints)
        """
        raw_constraints = {}
        if field_info is None:
            return raw_constraints

        if version == 2 and FieldInfo and isinstance(field_info, FieldInfo):
             # Pydantic v2: Check metadata and direct attributes
             if hasattr(field_info, "metadata") and field_info.metadata:
                 for item in field_info.metadata:
                      # Simplified check for common constraint types from annotated_types
                      # This could be made more robust by checking specific types
                      if hasattr(item, "gt"): raw_constraints["gt"] = item.gt
                      if hasattr(item, "ge"): raw_constraints["ge"] = item.ge
                      if hasattr(item, "lt"): raw_constraints["lt"] = item.lt
                      if hasattr(item, "le"): raw_constraints["le"] = item.le
                      if hasattr(item, "min_length"): raw_constraints["min_length"] = item.min_length
                      if hasattr(item, "max_length"): raw_constraints["max_length"] = item.max_length
                      if hasattr(item, "pattern"): raw_constraints["pattern"] = item.pattern

             # Check direct attributes as fallback or primary source
             for key in ["gt", "ge", "lt", "le", "min_length", "max_length", "pattern"]:
                 if key not in raw_constraints and hasattr(field_info, key):
                      value = getattr(field_info, key)
                      # Pydantic v2 sometimes uses PydanticUndefined
                      if value is not None and value is not PydanticUndefined:
                           raw_constraints[key] = value

             # Check json_schema_extra
             if hasattr(field_info, "json_schema_extra") and isinstance(field_info.json_schema_extra, dict):
                  for key in ["gt", "ge", "lt", "le", "min_length", "max_length", "pattern"]:
                       if key not in raw_constraints and key in field_info.json_schema_extra:
                            raw_constraints[key] = field_info.json_schema_extra[key]

        elif version == 1:
             # Pydantic v1: Check attributes on field_info and potentially __constraints__ on type
             v1_field_info = getattr(field_info, 'field_info', field_info) # Get FieldInfo if available

             for key in ["gt", "ge", "lt", "le", "min_length", "max_length"]:
                  if hasattr(v1_field_info, key) and getattr(v1_field_info, key) is not None:
                       raw_constraints[key] = getattr(v1_field_info, key)
             if hasattr(v1_field_info, "regex") and v1_field_info.regex is not None:
                  raw_constraints["pattern"] = v1_field_info.regex # Map regex to pattern

             # Check __constraints__ on the field's type (for conint etc.)
             field_type = getattr(field_info, 'outer_type_', None)
             if field_type and hasattr(field_type, '__constraints__') and isinstance(field_type.__constraints__, dict):
                  # Merge constraints, potentially overwriting field_info ones if more specific
                  # Be careful with merging logic if needed
                  for key, value in field_type.__constraints__.items():
                       if key not in raw_constraints: # Avoid overwriting for now
                           if key == 'regex': key = 'pattern' # Normalize
                           raw_constraints[key] = value
        else:
            # Cannot determine constraints for unknown/unsupported version
            pass

        return raw_constraints


    def _constraints_to_field_kwargs(self, constraints: Dict[str, Constraint]) -> Dict[str, Any]:
        """Convert core Constraint objects back to Pydantic Field keyword arguments."""
        kwargs = {}
        if not constraints:
            return kwargs

        for key, constraint in constraints.items():
            # Map based on the type of the Constraint object
            if isinstance(constraint, GreaterThanOrEqual): kwargs["ge"] = constraint.value
            elif isinstance(constraint, GreaterThan): kwargs["gt"] = constraint.value
            elif isinstance(constraint, LessThanOrEqual): kwargs["le"] = constraint.value
            elif isinstance(constraint, LessThan): kwargs["lt"] = constraint.value
            elif isinstance(constraint, MinLength): kwargs["min_length"] = constraint.value
            elif isinstance(constraint, MaxLength): kwargs["max_length"] = constraint.value
            elif isinstance(constraint, Pattern): kwargs["pattern"] = constraint.regex
            # Add mappings for other constraints if they are added

        return kwargs
```

**2. Create `politipo/core/conversion/strategies/pydantic_to_dict.py`**

This is a new file containing the `PydanticToDictStrategy`.

```python:politipo/core/conversion/strategies/pydantic_to_dict.py
# ./politipo/core/conversion/strategies/pydantic_to_dict.py

from typing import Any, Dict, Optional

try:
    from pydantic import BaseModel
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.engine import ConversionContext
from politipo.core.errors import ConversionError, PolitipoError


class PydanticToDictStrategy(ConversionStrategy):
    """Strategy for converting Pydantic model instances to Python dictionaries."""

    def __init__(self):
        self._pydantic_version = None # Cache version

    def _get_pydantic_version(self) -> Optional[int]:
        """Detect Pydantic version (cached)."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version
        try:
            if hasattr(BaseModel, "model_dump"): self._pydantic_version = 2
            elif hasattr(BaseModel, "dict"): self._pydantic_version = 1
            else: self._pydantic_version = None
            return self._pydantic_version
        except Exception:
            self._pydantic_version = None
            return None

    def can_handle(self, source: CanonicalType, target: CanonicalType) -> bool:
        """
        Check if this strategy can handle the conversion.
        Source must be a Pydantic model, target must be a dictionary.
        """
        # Check source is likely a Pydantic model (composite type)
        is_source_pydantic = (
            source.kind == "composite" and
            source.params.get("fields") is not None
            # We might need context.source_type_system.name == 'pydantic'
            # but source CanonicalType might not always originate directly from it.
            # Relying on structure for now.
        )
        # Check target is a dictionary
        is_target_dict = (target.kind == "container" and target.name == "dict")

        return is_source_pydantic and is_target_dict and PYDANTIC_INSTALLED

    def convert(self, value: Any, context: ConversionContext) -> Dict[str, Any]:
        """
        Perform the conversion from Pydantic model to dict.
        """
        if not PYDANTIC_INSTALLED:
             raise PolitipoError("Pydantic must be installed to use PydanticToDictStrategy.")
        if not isinstance(value, BaseModel):
             raise ConversionError(f"Input value is not a Pydantic BaseModel instance, got {type(value)}")

        version = self._get_pydantic_version()

        try:
            if version == 2:
                # Use model_dump for Pydantic v2
                # Consider dump options if needed (e.g., mode='json' vs 'python', exclude_none=True)
                return value.model_dump(mode='python') # mode='python' is usually desired for internal dicts
            elif version == 1:
                # Use dict() for Pydantic v1
                # Consider dict options if needed (e.g., exclude_none=True)
                return value.dict()
            else:
                raise ConversionError("Cannot determine Pydantic version for conversion.")
        except Exception as e:
            # Catch potential errors during dump/dict call
            raise ConversionError(f"Failed to convert Pydantic model to dict: {e}") from e
```

**3. Create `politipo/core/conversion/strategies/dict_to_pydantic.py`**

This is another new file, containing the `DictToPydanticStrategy`.

```python:politipo/core/conversion/strategies/dict_to_pydantic.py
# ./politipo/core/conversion/strategies/dict_to_pydantic.py

from typing import Any, Dict, Optional, Type

try:
    from pydantic import BaseModel, ValidationError
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy
    class ValidationError(Exception): pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.engine import ConversionContext
from politipo.core.errors import ConversionError, ConstraintViolationError, PolitipoError


class DictToPydanticStrategy(ConversionStrategy):
    """Strategy for converting Python dictionaries to Pydantic model instances."""

    def __init__(self):
        self._pydantic_version = None # Cache version

    def _get_pydantic_version(self) -> Optional[int]:
        """Detect Pydantic version (cached)."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version
        try:
            # Use model_validate (v2) vs parse_obj (v1) as indicator
            if hasattr(BaseModel, "model_validate"): self._pydantic_version = 2
            elif hasattr(BaseModel, "parse_obj"): self._pydantic_version = 1
            else: self._pydantic_version = None
            return self._pydantic_version
        except Exception:
             self._pydantic_version = None
             return None

    def can_handle(self, source: CanonicalType, target: CanonicalType) -> bool:
        """
        Check if this strategy can handle the conversion.
        Source must be dict, target must be Pydantic model.
        """
        is_source_dict = (source.kind == "container" and source.name == "dict")
        is_target_pydantic = (
            target.kind == "composite" and
            target.params.get("fields") is not None
            # Could add check: context.target_type_system.name == 'pydantic'
        )
        return is_source_dict and is_target_pydantic and PYDANTIC_INSTALLED

    def convert(self, value: Any, context: ConversionContext) -> BaseModel:
        """
        Perform the conversion from dict to Pydantic model instance.
        """
        if not PYDANTIC_INSTALLED:
             raise PolitipoError("Pydantic must be installed to use DictToPydanticStrategy.")
        if not isinstance(value, dict):
             raise ConversionError(f"Input value is not a dictionary, got {type(value)}")

        version = self._get_pydantic_version()

        try:
            # Get the target Pydantic model class from the TypeSystem
            target_model_class: Type[BaseModel] = context.target_type_system.from_canonical(context.target)
            if not isinstance(target_model_class, type) or not issubclass(target_model_class, BaseModel):
                 raise ConversionError(f"Target type '{context.target.name}' did not resolve to a Pydantic BaseModel class.")

            # Perform validation and instantiation based on version
            if version == 2:
                # Use model_validate for Pydantic v2
                # Consider strict mode from context? model_validate has its own context handling.
                instance = target_model_class.model_validate(value, strict=context.strict)
            elif version == 1:
                # Use parse_obj for Pydantic v1 (no explicit strict mode here)
                if context.strict:
                     # V1 strictness is less granular, parse_obj is inherently coercive
                     # We might need custom pre-validation if strict V1 is desired
                     print("Warning: Strict mode has limited effect in Pydantic v1 DictToPydanticStrategy.")
                instance = target_model_class.parse_obj(value)
            else:
                raise ConversionError("Cannot determine Pydantic version for conversion.")

            # TODO: Consider explicit handling for nested dict-to-model conversion if needed.
            # Pydantic usually handles dicts for nested models well during validation.
            # If issues arise, logic similar to TypeConverter._process_nested_pydantic_fields
            # might be needed here before calling validate/parse_obj.

            return instance

        except ValidationError as e:
            # Wrap Pydantic's validation error in our hierarchy
            # Distinguish between strict mode and non-strict mode behavior
            error_msg = f"Validation failed converting dict to Pydantic model '{target_model_class.__name__}': {e}"
            if context.strict:
                raise ConstraintViolationError(error_msg) from e
            else:
                # In non-strict mode, perhaps log a warning and return None or partial object?
                # For now, let's still raise, but maybe a different error type or logging.
                # Raising ConstraintViolationError seems appropriate even if not strict, as data didn't fit.
                print(f"Warning: {error_msg}") # Log warning in non-strict
                raise ConstraintViolationError(error_msg) from e # Or decide on alternative non-strict handling
        except Exception as e:
            # Catch other potential errors (e.g., TypeSystem issues, unexpected errors)
            raise ConversionError(f"Failed to convert dict to Pydantic model '{context.target.name}': {e}") from e
```

**4. Update `politipo/core/conversion/strategies/__init__.py`**

Finally, let's add the new strategies to the exports.

```python:politipo/core/conversion/strategies/__init__.py
from .base import ConversionStrategy
from .pandas_to_pydantic import DataFrameToModelStrategy
from .pydantic_to_dict import PydanticToDictStrategy # Added
from .dict_to_pydantic import DictToPydanticStrategy # Added

__all__ = [
    "ConversionStrategy",
    "DataFrameToModelStrategy",
    "PydanticToDictStrategy", # Added
    "DictToPydanticStrategy", # Added
    # Add other future strategies here
]
```

These changes should implement the Pydantic enhancements for Phase 2. The `PydanticTypeSystem` is now more robust, and we have dedicated strategies for converting between Pydantic models and dictionaries.

---

_**User**_

we got an error, can we check if everything above was applied?

---

_**Assistant**_

I'll help check if all the Phase 2 changes were properly applied. Let's verify each file:

1. First, let's check if `politipo/plugins/pydantic/types.py` was updated correctly:
- ✅ The file content matches our implementation
- ✅ Contains all the new constraint handling
- ✅ Has proper version detection
- ✅ Includes support for `date`, `datetime`, `decimal`, `EmailStr`, `SecretStr`

2. For `politipo/core/conversion/strategies/pydantic_to_dict.py`:
- ❌ I notice the file content shown is actually `DictToPydanticStrategy` instead of `PydanticToDictStrategy`
- Let's create the correct file:

```python:politipo/core/conversion/strategies/pydantic_to_dict.py
from typing import Any, Dict, Optional

try:
    from pydantic import BaseModel
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.engine import ConversionContext
from politipo.core.errors import ConversionError, PolitipoError


class PydanticToDictStrategy(ConversionStrategy):
    """Strategy for converting Pydantic model instances to Python dictionaries."""

    def __init__(self):
        self._pydantic_version = None # Cache version

    def _get_pydantic_version(self) -> Optional[int]:
        """Detect Pydantic version (cached)."""
        if not PYDANTIC_INSTALLED:
            return None
        if self._pydantic_version is not None:
            return self._pydantic_version
        try:
            if hasattr(BaseModel, "model_dump"): self._pydantic_version = 2
            elif hasattr(BaseModel, "dict"): self._pydantic_version = 1
            else: self._pydantic_version = None
            return self._pydantic_version
        except Exception:
            self._pydantic_version = None
            return None

    def can_handle(self, source: CanonicalType, target: CanonicalType) -> bool:
        """
        Check if this strategy can handle the conversion.
        Source must be a Pydantic model, target must be a dictionary.
        """
        # Check source is likely a Pydantic model (composite type)
        is_source_pydantic = (
            source.kind == "composite" and
            source.params.get("fields") is not None
            # We might need context.source_type_system.name == 'pydantic'
            # but source CanonicalType might not always originate directly from it.
            # Relying on structure for now.
        )
        # Check target is a dictionary
        is_target_dict = (target.kind == "container" and target.name == "dict")

        return is_source_pydantic and is_target_dict and PYDANTIC_INSTALLED

    def convert(self, value: Any, context: ConversionContext) -> Dict[str, Any]:
        """
        Perform the conversion from Pydantic model to dict.
        """
        if not PYDANTIC_INSTALLED:
             raise PolitipoError("Pydantic must be installed to use PydanticToDictStrategy.")
        if not isinstance(value, BaseModel):
             raise ConversionError(f"Input value is not a Pydantic BaseModel instance, got {type(value)}")

        version = self._get_pydantic_version()

        try:
            if version == 2:
                # Use model_dump for Pydantic v2
                # Consider dump options if needed (e.g., mode='json' vs 'python', exclude_none=True)
                return value.model_dump(mode='python') # mode='python' is usually desired for internal dicts
            elif version == 1:
                # Use dict() for Pydantic v1
                # Consider dict options if needed (e.g., exclude_none=True)
                return value.dict()
            else:
                raise ConversionError("Cannot determine Pydantic version for conversion.")
        except Exception as e:
            # Catch potential errors during dump/dict call
            raise ConversionError(f"Failed to convert Pydantic model to dict: {e}") from e
```

3. For `politipo/core/conversion/strategies/dict_to_pydantic.py`:
- ✅ The file exists and content matches our implementation
- ✅ Contains proper version detection and error handling
- ✅ Handles strict mode appropriately

4. For `politipo/core/conversion/strategies/__init__.py`:
- ✅ The file has been updated with both new strategies
- ✅ Exports are correctly defined

The issue appears to be that the `pydantic_to_dict.py` file contains the wrong class - it has `DictToPydanticStrategy` instead of `PydanticToDictStrategy`. Let's fix this by:

1. Creating the correct `pydantic_to_dict.py` file with the content I provided above
2. Moving the existing `DictToPydanticStrategy` to `dict_to_pydantic.py` if it's not already there

Would you like me to help you make these corrections?

---

_**User**_

check console output

---

_**Assistant**_

Ah, I see the issue now. We have a circular import problem in the codebase. Here's the circular dependency chain:

1. `politipo/core/conversion/__init__.py` imports from `engine.py`
2. `engine.py` imports from `strategies/base.py`
3. `strategies/__init__.py` imports from `pandas_to_pydantic.py`
4. `pandas_to_pydantic.py` tries to import `ConversionContext` from `engine.py`

Let's fix this circular dependency. Here's how we should restructure:

1. First, let's move `ConversionContext` to a separate file to break the cycle:

```python:politipo/core/conversion/context.py
from dataclasses import dataclass
from typing import Optional, Any
from politipo.core.types import TypeSystem, CanonicalType

@dataclass
class ConversionContext:
    """Context for conversion operations."""
    source: CanonicalType
    target: CanonicalType
    source_type_system: Optional[TypeSystem] = None
    target_type_system: Optional[TypeSystem] = None
    strict: bool = True
    metadata: dict = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
```

2. Then update the imports in affected files:

```python:politipo/core/conversion/engine.py
from typing import Any, Dict, List, Optional, Type
from politipo.core.types import TypeSystem, CanonicalType
from politipo.core.errors import ConversionError
from .context import ConversionContext  # Updated import
from .strategies.base import ConversionStrategy
```

```python:politipo/core/conversion/strategies/pandas_to_pydantic.py
from typing import Any, Dict, Optional, Type

try:
    import pandas as pd
    PANDAS_INSTALLED = True
except ImportError:
    PANDAS_INSTALLED = False
    pd = None

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.context import ConversionContext  # Updated import
from politipo.core.errors import ConversionError, PolitipoError
```

```python:politipo/core/conversion/strategies/pydantic_to_dict.py
from typing import Any, Dict, Optional

try:
    from pydantic import BaseModel
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.context import ConversionContext  # Updated import
from politipo.core.errors import ConversionError, PolitipoError
```

```python:politipo/core/conversion/strategies/dict_to_pydantic.py
from typing import Any, Dict, Optional, Type

try:
    from pydantic import BaseModel, ValidationError
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy
    class ValidationError(Exception): pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.context import ConversionContext  # Updated import
from politipo.core.errors import ConversionError, ConstraintViolationError, PolitipoError
```

3. Update `politipo/core/conversion/__init__.py`:

```python:politipo/core/conversion/__init__.py
from .engine import ConversionEngine
from .context import ConversionContext

__all__ = ["ConversionEngine", "ConversionContext"]
```

This restructuring should resolve the circular import issue by:
1. Moving `ConversionContext` to its own module
2. Updating all imports to reference the new location
3. Ensuring the dependency graph is acyclic

Would you like me to help implement these changes?

---

_**User**_

check output again please 

---

_**Assistant**_

Ah yes, now I can see the exact error in the traceback:

```
ImportError: cannot import name 'ConversionContext' from partially initialized module 'politipo.core.conversion.engine' (most likely due to a circular import)
```

Here's the circular import chain:
1. `__init__.py` imports from `engine.py`
2. `engine.py` imports from `strategies/base.py`
3. `strategies/__init__.py` imports from `pandas_to_pydantic.py`
4. `pandas_to_pydantic.py` tries to import `ConversionContext` from `engine.py`

Let's fix this by:

1. First, create a new file for `ConversionContext`:

```python:politipo/core/conversion/context.py
from dataclasses import dataclass
from typing import Optional
from politipo.core.types import CanonicalType, TypeSystem

@dataclass
class ConversionContext:
    """Context object passed to conversion strategies."""
    source: CanonicalType
    target: CanonicalType
    source_type_system: TypeSystem
    target_type_system: TypeSystem
    strict: bool = True
```

2. Update `engine.py` to import from context:

```python:politipo/core/conversion/engine.py
from typing import Dict, Type, Any, Optional, Union, List
from politipo.core.types import CanonicalType, TypeSystem
from politipo.core.conversion.graph import TypeGraph
from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.conversion.context import ConversionContext  # Updated import
```

3. Update `pandas_to_pydantic.py` to import from context:

```python:politipo/core/conversion/strategies/pandas_to_pydantic.py
from functools import lru_cache
from typing import Any, Type, Dict, List, Tuple
import pandas as pd
from pydantic import BaseModel, ValidationError

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.context import ConversionContext  # Updated import
from politipo.core.errors import ConversionError
```

4. Update `pydantic_to_dict.py` to import from context:

```python:politipo/core/conversion/strategies/pydantic_to_dict.py
from typing import Any, Dict, Optional

try:
    from pydantic import BaseModel
    PYDANTIC_INSTALLED = True
except ImportError:
    PYDANTIC_INSTALLED = False
    class BaseModel: pass # Dummy

from politipo.core.conversion.strategies.base import ConversionStrategy
from politipo.core.types import CanonicalType
from politipo.core.conversion.context import ConversionContext  # Updated import
from politipo.core.errors import ConversionError, PolitipoError
```

5. Update `__init__.py` to import ConversionContext from the new location:

```python:politipo/core/conversion/__init__.py
from .engine import ConversionEngine
from .context import ConversionContext  # Updated import
from .graph import TypeGraph
from .strategies.base import ConversionStrategy
from .strategies.pandas_to_pydantic import DataFrameToModelStrategy

__all__ = [
    "ConversionEngine",
    "ConversionContext",
    "TypeGraph",
    "ConversionStrategy",
    "DataFrameToModelStrategy"
]
```

Would you like me to help implement these changes? This should resolve the circular import issue by:
1. Moving `ConversionContext` to its own module
2. Updating all imports to reference the new location
3. Breaking the circular dependency chain

---



---

